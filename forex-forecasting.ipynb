{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1707432,"sourceType":"datasetVersion","datasetId":130130}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bayramakdag/forex-forecasting?scriptVersionId=208878691\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import math\nimport pandas_datareader as web\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, Dense, LSTM\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.data.experimental import AUTOTUNE as AUTO\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-21T18:46:30.867289Z","iopub.execute_input":"2024-11-21T18:46:30.867675Z","iopub.status.idle":"2024-11-21T18:46:30.873837Z","shell.execute_reply.started":"2024-11-21T18:46:30.867641Z","shell.execute_reply":"2024-11-21T18:46:30.872666Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Veri setini yükleme\ndata_csv = pd.read_csv('/kaggle/input/eur-usd-forex-pair-historical-data-2002-2019/eurusd_hour.csv')\ndata_csv.set_index(['Date'], inplace=True)\ndata = data_csv.filter(['BC'])\n\nprint(\"Veri setinin ilk 5 satırı:\")\nprint(data.head())\n\n# Rastgele eksik veriler oluşturma fonksiyonu\ndef add_random_missing_values(dataframe: pd.DataFrame, missing_rate: float = 0.01, seed: int = 42) -> pd.DataFrame:\n\n    # Veri çerçevesinin kopyasını oluştur\n    df_missing = dataframe.copy()\n\n    # Veri çerçevesinin boyutunu ve eklenecek eksik veri sayısını hesapla\n    df_size = dataframe.size\n    num_missing = int(df_size * missing_rate)\n\n    # Rastgelelik için tohum ayarla\n    random.seed(seed)\n\n    # Rastgele hücrelere NaN değeri ekle\n    for _ in range(num_missing):\n        row_idx = random.randint(0, dataframe.shape[0] - 1)\n        col_idx = random.randint(0, dataframe.shape[1] - 1)\n        df_missing.iat[row_idx, col_idx] = np.nan\n\n    return df_missing\n\n# Eksik veri oranını rastgele %1 ile %3 arasında belirle\nmissing_rate = random.uniform(0.01, 0.03)\n\n# Fonksiyonu uygulayarak eksik veri ekle\ndata_with_missing = add_random_missing_values(data, missing_rate=missing_rate)\n\n# Eksik veri analizini yap\nmissing_data = data_with_missing.isnull()\nmissing_count = missing_data.sum()\ntotal_missing = missing_count.sum()\n\nprint(f\"\\nUygulanan eksik veri oranı: {missing_rate:.2%}\")\nprint(\"\\nHer sütundaki eksik veri sayısı:\")\nprint(missing_count)\nprint(f\"\\nToplam eksik veri sayısı: {total_missing}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T18:50:57.304841Z","iopub.execute_input":"2024-11-21T18:50:57.305271Z","iopub.status.idle":"2024-11-21T18:50:57.540327Z","shell.execute_reply.started":"2024-11-21T18:50:57.305234Z","shell.execute_reply":"2024-11-21T18:50:57.539147Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Veri setinin ilk 5 satırı:\n                BC\nDate              \n2005-05-02  1.2844\n2005-05-02  1.2842\n2005-05-02  1.2851\n2005-05-02  1.2851\n2005-05-02  1.2855\n\nUygulanan eksik veri oranı: 2.44%\n\nHer sütundaki eksik veri sayısı:\nBC    2238\ndtype: int64\n\nToplam eksik veri sayısı: 2238\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":" EUR/USD tarihsel döviz kuru veri setine rastgele eksik veriler ekleyeceğiz ve ardından bu eksik verileri analiz edeceğiz. Bu, veri ön işleme ve eksik veri analizi için önemli bir adımdır.\n  Kaggle veri setini yüklüyoruz ve yalnızca \"BC\" (kapanış fiyatı) sütununu analiz etmek üzere seçiyoruz.\n  Daha sonrasında, veri setine belirli bir oran (%1 - %3) arasında rastgele eksik veriler ekler. Eksik veri oranını rastgele %1 ile %3 arasında bir değer olarak belirliyor ve veri setine uyguluyoruz.\n  Son olarak, eksik veri eklenen veri setinde eksik verileri analiz ediyoruz:","metadata":{}},{"cell_type":"code","source":"# Görselleştirme\nplt.figure(figsize=(20,10))\nplt.plot(data['BC'])\nplt.title('USD&EUR Tarih')\nplt.xlabel('Tarih')\nplt.ylabel('Kapanis Fiyati ($)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-21T18:41:04.131161Z","iopub.execute_input":"2024-11-21T18:41:04.13155Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"LSTM modeli, zaman serisi tahmini yapmak için eğitilecek. Modelin başarısını, eğitim ve doğrulama veri setlerinin görselleştirilmesiyle değerlendireceğiz.","metadata":{}},{"cell_type":"code","source":"# Normalizasyon\ndataset = data.values\ntraining_data_len = math.ceil(len(dataset) * 0.95)\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled_data = scaler.fit_transform(dataset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu bölümde, veri seti üzerinde normalizasyon işlemi yapılır. Normalizasyon, verilerin belirli bir aralığa (bu durumda 0 ile 1 arasında) dönüştürülmesi işlemidir. Bu işlem, özellikle makine öğrenmesi modellerinde, özellikle sinir ağları gibi algoritmalarda daha hızlı ve verimli sonuçlar elde etmek için yaygın olarak kullanılır. \n\nİlk adımda ki data dataframe'ndeki değerler (özellikler) bir NumPy dizisine (`dataset`) dönüştürülür. Bu sayede veri üzerinde işlemler daha hızlı bir şekilde yapılabilir.","metadata":{}},{"cell_type":"code","source":"# Eğitim verisi oluşturma\nwindow = 10\ntrain_data = scaled_data[0:training_data_len, :]\nx_train, y_train = [], []\n\nfor i in range(window, len(train_data)):\n    x_train.append(train_data[i - window:i, 0])\n    y_train.append(train_data[i, 0])\n\nx_train, y_train = np.array(x_train), np.array(y_train)\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu adımda, eğitim verisi hazırlanır ve modelin öğrenebilmesi için uygun formata dönüştürülür. Bu süreç, zaman serisi verisiyle çalışırken, önceki değerlerin gelecekteki değerleri tahmin etmek için nasıl kullanılacağını belirler. Bu örnekte, LSTM (Long Short-Term Memory modeline uygun bir eğitim veri seti oluşturuluyor.\n\nwindow parametresi, modelin her bir tahmin için kaç geçmiş gözlem kullanacağını belirler. Bu örnekte, 30 geçmiş gözlem kullanılarak tahmin yapılacak.","metadata":{}},{"cell_type":"code","source":"# Model oluşturma\nmodel = Sequential([\n    LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)),\n    LSTM(50, return_sequences=False),\n    Dense(50),\n    Dense(1)\n])\nmodel.compile(optimizer='adam', loss='mean_squared_error')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu katman, modelin ilk LSTM katmanıdır ve 50 birim içerir.\nreturn_sequences = True parametresi, bu katmandan çıkan her zaman adımında bir dizi değer döndüreceğini belirtir. Bu, bir sonraki LSTM katmanına çoklu zaman adımlarının aktarılmasını sağlar.\n\nBu, modelin beklediği giriş verisinin şeklidir. Buradaki x_train.shape[1], her bir zaman adımındaki gözlem sayısını ifade eder ve 1 ise her adım için tek bir özelliği belirtir.","metadata":{}},{"cell_type":"code","source":"# Modeli eğitme\nmodel.fit(x_train, y_train, batch_size=30, epochs=10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu adımda, LSTM modelini eğitim verisi ile eğitmek için model.fit() fonksiyonu kullanılır. Model, eğitim verisi üzerinde 30 örnekten oluşan küçük gruplarla (batch_size) ve 10 epoch boyunca eğitilecektir. \n\nmodel.fit() fonksiyonu, modelin eğitim verisi (x_train) ve hedef verisi (y_train) ile eğitilmesini sağlar. Bu fonksiyon, modelin batch_size ve epochs gibi eğitim parametrelerini de alır.","metadata":{}},{"cell_type":"code","source":"# Test verisi\ntest_data = scaled_data[training_data_len - window:, :]\nx_test = []\ny_test = dataset[training_data_len:, :]\nfor i in range(window, len(test_data)):\n    x_test.append(test_data[i - window:i, 0])\n\nx_test = np.array(x_test)\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu adımda, modelin doğruluğunu test etmek için test verisi hazırlanır. Test verisi, eğitim verisinden farklı olarak, modelin daha önce görmediği verilerle tahminler yapmasını sağlar. Bu aşamada, test verisi normalleştirilmiş (scaled) hale getirilmiş ve uygun formata sokulmuştur.\n\nEğitim verisinden sonra gelen veriler test verisi olarak kullanılır. training_data_len - window ifadesi, test verisinin başlangıcını belirler. Burada window parametresi, geçmiş verileri kullanarak yapılan tahminlerdeki zaman adımı uzunluğudur.","metadata":{}},{"cell_type":"code","source":"# Tahminler\npred = model.predict(x_test)\npred = scaler.inverse_transform(pred)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu adımda, eğitilmiş LSTM modeli, test verisi üzerinde tahminlerde bulunur. Model, test verisindeki her örnek için gelecekteki değeri tahmin eder ve bu tahminler, normalize edilmiş (scaled) formatta olduğu için orijinal ölçekteki değerlere geri dönüştürülür.\n\nTest verisi olan x_test üzerinde modelin tahmin yapması sağlanır. Model, her bir giriş örneği için tek bir tahmin değeri üretir. ","metadata":{}},{"cell_type":"code","source":"train = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Tahminler'] = pred\n\nplt.figure(figsize=(20,10))\nplt.plot(train['BC'])\nplt.plot(valid[['BC', 'Tahminler']])\nplt.title('Model')\nplt.xlabel('Tarih')\nplt.ylabel('Kapanis Fiyati ($)')\nplt.legend(['Eğitim', 'Gerçek', 'Tahmin'])\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu adımda, modelin tahmin sonuçları, gerçek verilerle karşılaştırılarak görselleştirilir. Eğitim verisi (train), gerçek test verisi (valid) ve modelin tahmin ettiği değerler (Tahminler) bir grafik üzerinde gösterilir.\nEğitim veri kümesinin ilk training_data_len kadar verisi seçilir.\n\nEğitim verisinden sonra gelen veri kısmı test verisi olarak kullanılır.","metadata":{}}]}